import numpy as np
import pandas as pd
from typing import Union

from tpot import TPOTClassifier, TPOTRegressor


def _fit_tpot(
    tpot: Union[TPOTClassifier, TPOTRegressor],
    fit_X_train: Union[pd.DataFrame, np.array],
    fit_y_train: Union[pd.DataFrame, np.array],
    fit_X_val: Union[pd.DataFrame, np.array],
    fit_y_val: Union[pd.DataFrame, np.array],
    path_to_export,
):
    """
    This function train the tpot pipeline, print the pipeline validation score and predict export the python file
    generated by the tpot library

    Args:
        tpot: represents the tpot model
        fit_X_train: represent the feature training dataset
        fit_y_train: represent the target training dataset
        fit_X_val: represent the feature validation dataset
        fit_y_val: represent the target validation dataset
        path_to_export: it's the path to store the python file

    Returns: This function return the trained tpot pipeline with the prediction
    """

    # train the pipeline
    tpot.fit(np.array(fit_X_train), np.array(fit_y_train).ravel())

    # print the test score
    print(tpot.score(np.array(fit_X_val), np.array(fit_y_val).ravel()))

    # create the probability array for the test set
    prediction = tpot.predict(np.array(fit_X_val))

    # export the model as a python file in the path set using the pipeline name as name of the folder
    tpot.export(path_to_export)

    return tpot, prediction


def _get_custom_cv(X_train, y_train, X_val, y_val):
    """
    This function generate the custom validation set that will be used by tpot to train tpot pipeline. To do so
    we need to merge training and validation together and get indexes that separate train and validation

    Args:
        X_train: it's the training dataset containing only features
        y_train: it's the training target
        X_val: it's the validation dataset containing only features
        y_val: it's the validation target

    Returns:
    """
    # reset indexes
    l_x_train = pd.DataFrame(X_train).reset_index(drop=True)
    l_y_train = pd.DataFrame(y_train).reset_index(drop=True)
    l_x_val = pd.DataFrame(X_val).reset_index(drop=True)
    l_y_val = pd.DataFrame(y_val).reset_index(drop=True)

    # Concat 2 dataframes to
    final_x_train = pd.concat([l_x_train, l_x_val])
    final_x_train = pd.DataFrame(final_x_train).reset_index(drop=True)
    final_y_train = pd.concat([l_y_train, l_y_val])
    final_y_train = pd.DataFrame(final_y_train).reset_index(drop=True)

    # since we merged the 2 dataframes and resented the indexes, now we can specify what are the indices of the
    # train and the validation
    train_indices = list(range(l_x_train.index[-1] + 1))
    test_indices = list(range((l_x_train.index[-1] + 1), (final_x_train.index[-1] + 1)))

    custom_cv = list()
    custom_cv.append((train_indices, test_indices))
    print(final_x_train.columns)

    # we add to a list of arrays the train index and the validation index that we will use for training and validation
    return custom_cv, final_x_train, final_y_train